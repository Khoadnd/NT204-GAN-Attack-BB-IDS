{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "from const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.read_feather('dataset/train.feather')\n",
    "\n",
    "X_probe = X[X['label'] == 1] # get probe attack samples\n",
    "y_probe = np.ones_like(X_probe['label'])\n",
    "X_probe = X_probe.drop(columns=['label'])\n",
    "\n",
    "y = X.iloc[:, -1]\n",
    "X = X.iloc[:, :-1]\n",
    "\n",
    "X = X.loc[:, content_feature]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25, stratify=y)\n",
    "\n",
    "train_target = torch.tensor(y_train.values.astype('float32'))\n",
    "train = torch.tensor(X_train.values.astype('float32'))\n",
    "train_tensor = TensorDataset(train, train_target)\n",
    "train_loader = DataLoader(train_tensor, batch_size=64, shuffle=True)\n",
    "\n",
    "test_target = torch.tensor(y_test.values.astype('float32'))\n",
    "test = torch.tensor(X_test.values.astype('float32'))\n",
    "test_tensor = TensorDataset(test, test_target)\n",
    "test_loader = DataLoader(test_tensor, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "  def __init__(self, in_feature) -> None:\n",
    "    super().__init__()\n",
    "    self.disc = nn.Sequential(\n",
    "      nn.Linear(in_feature, 128),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(128, 1),\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.disc(x)\n",
    "  \n",
    "class Generator(nn.Module):\n",
    "  def __init__(self, z_dim, out_dim) -> None:\n",
    "    super().__init__()\n",
    "    self.gen = nn.Sequential(\n",
    "      nn.Linear(z_dim, 128),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(128, out_dim),\n",
    "      nn.Tanh()\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.gen(x)\n",
    "  \n",
    "def initialize_weight(model):\n",
    "  for m in model.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "      nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "  \n",
    "# load blackbox model\n",
    "import pickle\n",
    "\n",
    "with open('models/ExtraTrees.pickle', 'rb') as f:\n",
    "  blackbox = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (disc): Sequential(\n",
       "    (0): Linear(in_features=13, out_features=128, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "z_dim = in_feature = train.shape[1]\n",
    "\n",
    "critic = Critic(in_feature).to(device)\n",
    "gen = Generator(z_dim, in_feature).to(device)\n",
    "initialize_weight(critic)\n",
    "initialize_weight(gen)\n",
    "\n",
    "num_epochs = 15\n",
    "batch_size = 64\n",
    "n_critics = 5\n",
    "clipping_value = 0.01\n",
    "\n",
    "ids_loss = nn.CrossEntropyLoss()\n",
    "lambda_ = 0.3\n",
    "\n",
    "lr = 1e-4\n",
    "opt_critic = optim.RMSprop(critic.parameters(), lr=lr)\n",
    "opt_gen = optim.RMSprop(gen.parameters(), lr=lr)\n",
    "\n",
    "gen.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/15] \\ Loss D: -0.0008, loss G: -0.0088\n",
      "Epoch [1/15] \\ Loss D: -0.0002, loss G: -0.0132\n",
      "Epoch [2/15] \\ Loss D: -0.0001, loss G: -0.0125\n",
      "Epoch [3/15] \\ Loss D: -0.0001, loss G: -0.0128\n",
      "Epoch [4/15] \\ Loss D: -0.0003, loss G: -0.0133\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  for batch_idx, (real, _) in enumerate(train_loader):\n",
    "    real = real.to(device)\n",
    "    \n",
    "    for _ in range(n_critics):\n",
    "      noise = torch.randn(batch_size, z_dim).to(device)\n",
    "      fake = gen(noise)\n",
    "      critic_real = critic(real)\n",
    "      critic_fake = critic(fake)\n",
    "      loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "      critic.zero_grad()\n",
    "      loss_critic.backward(retain_graph=True)\n",
    "      opt_critic.step()\n",
    "      \n",
    "      for p in critic.parameters():\n",
    "        p.data.clamp_(-clipping_value, clipping_value)\n",
    "    \n",
    "    output = critic(fake)\n",
    "    with torch.no_grad():\n",
    "      a = fake.numpy()\n",
    "      a = pd.DataFrame(a, columns=content_feature, dtype='float32')\n",
    "      b = X_probe.sample(n=64) \n",
    "      b = b.reset_index(drop=True)\n",
    "      b = b.astype('float32')\n",
    "      b.loc[:, content_feature] = a.loc[:, content_feature]\n",
    "      bb = torch.tensor(blackbox.predict(\n",
    "          b).astype('float32')).to(device)\n",
    "    loss_gen = -torch.mean(output) + lambda_ * ids_loss(bb, torch.zeros_like(bb))\n",
    "    gen.zero_grad()\n",
    "    loss_gen.backward()\n",
    "    opt_gen.step()\n",
    "    \n",
    "    \n",
    "    if batch_idx == 0:\n",
    "      print(\n",
    "        f\"Epoch [{epoch}/{num_epochs}] \\ \"\n",
    "        f\"Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
    "      )``"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
