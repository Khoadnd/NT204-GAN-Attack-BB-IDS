{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import typing\n",
    "import numpy as np\n",
    "from const import *\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipConstraint(tf.keras.constraints.Constraint):\n",
    "  def __init__(self, clip_value) -> None:\n",
    "    super().__init__()\n",
    "    self.clip_value = clip_value\n",
    "    \n",
    "  def __call__(self, weights) -> tf.Tensor:\n",
    "    return tf.clip_by_value(weights, -self.clip_value, self.clip_value)\n",
    "\n",
    "def loss(y_true, y_pred) -> tf.Tensor:\n",
    "  return tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "def Critic(in_feature : int) -> tf.keras.models.Sequential:\n",
    "  init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "  const = ClipConstraint(0.01)\n",
    "  model = tf.keras.models.Sequential(\n",
    "    layers=[\n",
    "      tf.keras.layers.Dense(units=128, kernel_initializer=init, kernel_constraint=const, input_shape=(in_feature,)),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "      \n",
    "      tf.keras.layers.Dense(units=128, kernel_initializer=init, kernel_constraint=const),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "      \n",
    "      tf.keras.layers.Dense(units=1, kernel_initializer=init, kernel_constraint=const)\n",
    "    ],\n",
    "    name='Critic'\n",
    "  )\n",
    "  \n",
    "  opt = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "  model.compile(loss=loss, optimizer=opt)\n",
    "  return model\n",
    "\n",
    "def Generator(latent_dim : int, out_feature : int) -> tf.keras.models.Sequential:\n",
    "  init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "  model = tf.keras.models.Sequential(\n",
    "    layers=[\n",
    "      tf.keras.layers.Dense(units=128, kernel_initializer=init, input_shape=(latent_dim,)),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "      \n",
    "      tf.keras.layers.Dense(units=128, kernel_initializer=init),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "      \n",
    "      tf.keras.layers.Dense(units=out_feature, kernel_initializer=init)\n",
    "    ],\n",
    "    name='Generator'\n",
    "  )\n",
    "  \n",
    "  return model\n",
    "\n",
    "def attackGAN(generator : tf.keras.models.Sequential, critic: tf.keras.models.Sequential) -> tf.keras.models.Sequential:\n",
    "  critic.trainable = False\n",
    "  model = tf.keras.models.Sequential(\n",
    "    layers=[\n",
    "      generator,\n",
    "      critic\n",
    "    ],\n",
    "    name='attackGAN'\n",
    "  )\n",
    "  \n",
    "  opt = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "  model.compile(loss=loss, optimizer=opt)\n",
    "  return model\n",
    "\n",
    "def Blackbox(path : str) -> any:\n",
    "  with open(path, 'rb') as handle:\n",
    "    return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path : str) -> pd.DataFrame:\n",
    "  X = pd.read_feather(path)\n",
    "  # Select only probe attack\n",
    "  X = X.drop(columns=['label'])[X['label'] == 1].reset_index(drop=True).astype('float32')\n",
    "  return X\n",
    "\n",
    "def mapping(fake : np.ndarray) -> np.ndarray:\n",
    "  fake = pd.DataFrame(fake, columns=content_feature, dtype='float32')\n",
    "  real = dataset.sample(n=fake.shape[0]).reset_index(drop=True).astype('float32')\n",
    "  real.loc[:, content_feature] = fake.loc[:, content_feature]\n",
    "  \n",
    "  return real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.disable_interactive_logging()\n",
    "dataset = load_dataset('dataset/train.feather')\n",
    "latent_dim = 13\n",
    "critic = Critic(13)\n",
    "gen = Generator(latent_dim, 13)\n",
    "blackbox = Blackbox('models/ExtraTrees.pickle')\n",
    "\n",
    "opt_critic = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "opt_gen = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "\n",
    "n_epochs = 200\n",
    "n_batch = 64\n",
    "\n",
    "n_critics = 5\n",
    "\n",
    "lambada = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_sample):\n",
    "  for _ in range(n_critics):\n",
    "    noise = tf.random.normal((n_batch, latent_dim))\n",
    "    fake = gen(noise, training=False)\n",
    "    with tf.GradientTape() as tape:\n",
    "      critic_real = critic(real_sample, training=True)\n",
    "      critic_fake = critic(fake, training=True)\n",
    "      loss_critic = -(tf.reduce_mean(critic_real) -\n",
    "                      tf.reduce_mean(critic_fake))\n",
    "    \n",
    "    grad_critic = tape.gradient(loss_critic, critic.trainable_weights)\n",
    "    opt_critic.apply_gradients(zip(grad_critic, critic.trainable_weights))\n",
    "\n",
    "  # training generator\n",
    "  noise = tf.random.normal((n_batch, latent_dim))\n",
    "  out_map = tf.numpy_function(mapping, [fake], Tout=tf.float32)\n",
    "  out_blackbox = tf.numpy_function(blackbox.predict, [out_map], Tout=tf.int64)\n",
    "  out_blackbox = tf.one_hot(out_blackbox, depth=5)\n",
    "  target = tf.zeros(n_batch, dtype='int64')  # zero is normal\n",
    "  loss_blackbox = tf.keras.losses.SparseCategoricalCrossentropy()(target, out_blackbox)\n",
    "  with tf.GradientTape() as tape:\n",
    "    out_gen = gen(noise, training=True)\n",
    "    out_critic = critic(out_gen, training=False)\n",
    "    loss_gen = -tf.reduce_mean(out_critic) + lambada * loss_blackbox\n",
    "  \n",
    "  grad_gen = tape.gradient(loss_gen, gen.trainable_weights)\n",
    "  opt_gen.apply_gradients(zip(grad_gen, gen.trainable_weights))\n",
    "  return loss_critic, loss_gen, loss_blackbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss Critic: -0.0025120393838733435, Loss Gen: 7.93308162689209, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 1, Loss Critic: -0.22666524350643158, Loss Gen: 7.868237495422363, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 2, Loss Critic: -0.27726951241493225, Loss Gen: 7.615461826324463, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 3, Loss Critic: -0.4072169065475464, Loss Gen: 7.929147720336914, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 4, Loss Critic: -0.3329728841781616, Loss Gen: 7.706272125244141, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 5, Loss Critic: -0.4791835844516754, Loss Gen: 7.998869895935059, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 6, Loss Critic: -0.3873544931411743, Loss Gen: 7.819278240203857, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 7, Loss Critic: -0.6097633242607117, Loss Gen: 8.112804412841797, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 8, Loss Critic: -0.8760426044464111, Loss Gen: 8.03581428527832, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 9, Loss Critic: -0.5944784879684448, Loss Gen: 8.183330535888672, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 10, Loss Critic: -1.05397629737854, Loss Gen: 8.313618659973145, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 11, Loss Critic: -0.8474117517471313, Loss Gen: 7.883637428283691, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 12, Loss Critic: -1.0447736978530884, Loss Gen: 8.193163871765137, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 13, Loss Critic: -1.0528581142425537, Loss Gen: 8.485340118408203, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 14, Loss Critic: -1.1231074333190918, Loss Gen: 8.521469116210938, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 15, Loss Critic: -1.1220312118530273, Loss Gen: 8.74293041229248, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 16, Loss Critic: -1.047071099281311, Loss Gen: 8.508350372314453, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 17, Loss Critic: -1.4585514068603516, Loss Gen: 8.794906616210938, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 18, Loss Critic: -1.609848141670227, Loss Gen: 8.919835090637207, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 19, Loss Critic: -1.3845182657241821, Loss Gen: 8.442368507385254, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 20, Loss Critic: -1.3064175844192505, Loss Gen: 8.367439270019531, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 21, Loss Critic: -1.4288642406463623, Loss Gen: 8.438407897949219, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 22, Loss Critic: -1.3906052112579346, Loss Gen: 9.032206535339355, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 23, Loss Critic: -1.294396996498108, Loss Gen: 8.531204223632812, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 24, Loss Critic: -1.654618263244629, Loss Gen: 8.729925155639648, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 25, Loss Critic: -2.0959343910217285, Loss Gen: 8.884878158569336, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 26, Loss Critic: -1.1750998497009277, Loss Gen: 9.426275253295898, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 27, Loss Critic: -2.180478572845459, Loss Gen: 9.66796875, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 28, Loss Critic: -1.6524710655212402, Loss Gen: 11.432558059692383, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 29, Loss Critic: -1.565303087234497, Loss Gen: 9.657301902770996, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 30, Loss Critic: -1.8262720108032227, Loss Gen: 10.133610725402832, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 31, Loss Critic: -2.1080758571624756, Loss Gen: 9.797648429870605, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 32, Loss Critic: -2.178462505340576, Loss Gen: 9.817178726196289, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 33, Loss Critic: -1.8416597843170166, Loss Gen: 9.679315567016602, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 34, Loss Critic: -1.8062266111373901, Loss Gen: 9.099209785461426, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 35, Loss Critic: -2.6523752212524414, Loss Gen: 9.845351219177246, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 36, Loss Critic: -2.15537166595459, Loss Gen: 9.25360107421875, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 37, Loss Critic: -2.438795566558838, Loss Gen: 9.397205352783203, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 38, Loss Critic: -2.421572685241699, Loss Gen: 10.211307525634766, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 39, Loss Critic: -2.827179431915283, Loss Gen: 9.520853042602539, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 40, Loss Critic: -2.949758529663086, Loss Gen: 9.462180137634277, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 41, Loss Critic: -1.8540918827056885, Loss Gen: 8.978692054748535, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 42, Loss Critic: -2.8584794998168945, Loss Gen: 9.494033813476562, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 43, Loss Critic: -2.821397542953491, Loss Gen: 9.418852806091309, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 44, Loss Critic: -2.326500415802002, Loss Gen: 9.024863243103027, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 45, Loss Critic: -2.0282013416290283, Loss Gen: 11.50754165649414, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 46, Loss Critic: -3.234368324279785, Loss Gen: 9.59400463104248, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 47, Loss Critic: -3.1798417568206787, Loss Gen: 9.891766548156738, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 48, Loss Critic: -3.1106090545654297, Loss Gen: 10.398919105529785, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 49, Loss Critic: -3.3298373222351074, Loss Gen: 10.00299072265625, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 50, Loss Critic: -3.261310577392578, Loss Gen: 9.218643188476562, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 51, Loss Critic: -2.069777011871338, Loss Gen: 9.903799057006836, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 52, Loss Critic: -1.7052499055862427, Loss Gen: 9.122268676757812, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 53, Loss Critic: -2.868903636932373, Loss Gen: 8.92920970916748, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 54, Loss Critic: -3.10713529586792, Loss Gen: 10.256732940673828, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 55, Loss Critic: -3.5698273181915283, Loss Gen: 9.403525352478027, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 56, Loss Critic: -3.51878023147583, Loss Gen: 9.961891174316406, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 57, Loss Critic: -3.5547258853912354, Loss Gen: 9.289999961853027, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 58, Loss Critic: -2.9200897216796875, Loss Gen: 9.485559463500977, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 59, Loss Critic: -2.4781956672668457, Loss Gen: 9.818857192993164, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 60, Loss Critic: -3.3594744205474854, Loss Gen: 9.488204002380371, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 61, Loss Critic: -2.827676773071289, Loss Gen: 9.051483154296875, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 62, Loss Critic: -3.047699451446533, Loss Gen: 9.728778839111328, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 63, Loss Critic: -3.197726011276245, Loss Gen: 9.604381561279297, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 64, Loss Critic: -4.097609519958496, Loss Gen: 10.096270561218262, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 65, Loss Critic: -3.3245582580566406, Loss Gen: 8.98963737487793, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 66, Loss Critic: -1.81830894947052, Loss Gen: 9.596985816955566, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 67, Loss Critic: -3.418447971343994, Loss Gen: 9.088040351867676, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 68, Loss Critic: -4.21303129196167, Loss Gen: 8.65053939819336, Loss Blackbox: 15.110713958740234\n",
      "Epoch: 69, Loss Critic: -3.3622348308563232, Loss Gen: 9.92391586303711, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 70, Loss Critic: -3.647979974746704, Loss Gen: 9.341663360595703, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 71, Loss Critic: -3.420752763748169, Loss Gen: 9.311585426330566, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 72, Loss Critic: -3.164222002029419, Loss Gen: 9.088587760925293, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 73, Loss Critic: -3.4459421634674072, Loss Gen: 9.304265975952148, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 74, Loss Critic: -3.233607292175293, Loss Gen: 8.977149963378906, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 75, Loss Critic: -3.3789281845092773, Loss Gen: 9.242317199707031, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 76, Loss Critic: -1.951735496520996, Loss Gen: 8.786239624023438, Loss Blackbox: 15.362560272216797\n",
      "Epoch: 77, Loss Critic: -1.8335721492767334, Loss Gen: 8.971736907958984, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 78, Loss Critic: -1.8341337442398071, Loss Gen: 8.967153549194336, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 79, Loss Critic: -3.167947769165039, Loss Gen: 8.932439804077148, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 80, Loss Critic: -3.094703197479248, Loss Gen: 9.215654373168945, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 81, Loss Critic: -1.7394609451293945, Loss Gen: 8.614192962646484, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 82, Loss Critic: -3.463449001312256, Loss Gen: 9.030088424682617, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 83, Loss Critic: -3.26531982421875, Loss Gen: 8.872991561889648, Loss Blackbox: 14.607023239135742\n",
      "Epoch: 84, Loss Critic: -3.629398822784424, Loss Gen: 8.826371192932129, Loss Blackbox: 15.614404678344727\n",
      "Epoch: 85, Loss Critic: -3.3009567260742188, Loss Gen: 9.530036926269531, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 86, Loss Critic: -4.059994697570801, Loss Gen: 9.550979614257812, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 87, Loss Critic: -1.7131396532058716, Loss Gen: 8.082291603088379, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 88, Loss Critic: -1.7110724449157715, Loss Gen: 8.396946907043457, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 89, Loss Critic: -3.857664108276367, Loss Gen: 8.438114166259766, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 90, Loss Critic: -1.5970747470855713, Loss Gen: 8.641135215759277, Loss Blackbox: 15.36255931854248\n",
      "Epoch: 91, Loss Critic: -3.21807861328125, Loss Gen: 8.87474536895752, Loss Blackbox: 16.11809539794922\n",
      "Epoch: 92, Loss Critic: -4.284792900085449, Loss Gen: 9.207021713256836, Loss Blackbox: 15.866250038146973\n",
      "Epoch: 93, Loss Critic: -3.339974880218506, Loss Gen: 8.837820053100586, Loss Blackbox: 15.36255931854248\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m     10\u001b[0m   \u001b[39mfor\u001b[39;00m step, X_real \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data):\n\u001b[0;32m---> 11\u001b[0m     loss_critic, loss_gen, loss_blackbox \u001b[39m=\u001b[39m train_step(X_real)\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m       \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Loss Critic: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Loss Gen: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Loss Blackbox: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     15\u001b[0m           epoch, loss_critic, loss_gen, loss_blackbox))\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambada = 0.5\n",
    "# ids_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_data = dataset.loc[:, content_feature]\n",
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "    tf.convert_to_tensor(train_data.values))\n",
    "train_data = train_data.shuffle(buffer_size=1024).batch(n_batch)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  for step, X_real in enumerate(train_data):\n",
    "    loss_critic, loss_gen, loss_blackbox = train_step(X_real)\n",
    "\n",
    "    if step == 0:\n",
    "      print('Epoch: {}, Loss Critic: {}, Loss Gen: {}, Loss Blackbox: {}'.format(\n",
    "          epoch, loss_critic, loss_gen, loss_blackbox))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
